{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBJgySvnYHXJ/A366epnU8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uzum4ke/Topological-Quantum-Compilation/blob/main/RL_for_TQC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YjIlvqSVI1PA"
      },
      "outputs": [],
      "source": [
        "pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sb3-contrib"
      ],
      "metadata": {
        "id": "ys3lAAxyNDJX",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "!pip install cloud-tpu-client\n",
        "!pip install torch_xla[tpu] -f https://storage.googleapis.com/libtpu-releases/index.html\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "H8YdG_-c3_WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "\n",
        "# Check TPU device\n",
        "print(\"TPU device:\", xm.xla_device())\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available.\")\n",
        "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"GPU is not available. Make sure to enable GPU in the runtime settings.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAr0Zg6v4Ndg",
        "outputId": "dc7bb075-6893-4b45-da82-dbe4e0d592a1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU device: xla:0\n",
            "GPU is not available. Make sure to enable GPU in the runtime settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "#from scipy.linalg import sqrtm\n",
        "\n",
        "from stable_baselines3 import PPO, DQN\n",
        "from sb3_contrib import RecurrentPPO\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "\n",
        "from sympy import Matrix, symbols, eye, KroneckerProduct\n",
        "\n",
        "import warnings\n",
        "\n",
        "# Suppress RuntimeWarnings\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RNDRVNPoJBkf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################\n",
        "# Configuration and Hyperparameters\n",
        "######################################\n",
        "\n",
        "LEARNING_RATE = 1e-4\n",
        "ALPHA = 0.25  # Leakage weight\n",
        "BETA = 0.50   # Closeness weight\n",
        "GAMMA = 0.25  # Unitarity weight\n",
        "SEQUENCE_LENGTH = 100  # Number of compositions"
      ],
      "metadata": {
        "id": "LbdPJ75mYz9T"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def direct_sum(A, B):\n",
        "\n",
        "    # Helper function to convert input to a SymPy Matrix\n",
        "    def to_matrix(x):\n",
        "        if isinstance(x, Matrix):\n",
        "            return x\n",
        "        else:\n",
        "            # Assume x is a scalar, convert to 1x1 Matrix\n",
        "            return Matrix([[x]])\n",
        "\n",
        "    # Convert inputs to matrices\n",
        "    A_matrix = to_matrix(A)\n",
        "    B_matrix = to_matrix(B)\n",
        "\n",
        "    # Check if A_matrix is square\n",
        "    if A_matrix.rows != A_matrix.cols:\n",
        "        raise ValueError(f\"Matrix A is not square: {A_matrix.rows}x{A_matrix.cols}\")\n",
        "\n",
        "    # Check if B_matrix is square\n",
        "    if B_matrix.rows != B_matrix.cols:\n",
        "        raise ValueError(f\"Matrix B is not square: {B_matrix.rows}x{B_matrix.cols}\")\n",
        "\n",
        "    # Dimensions\n",
        "    N = A_matrix.rows\n",
        "    M = B_matrix.rows\n",
        "\n",
        "    # Create a zero matrix of size (N+M) x (N+M)\n",
        "    C = Matrix.zeros(N + M, N + M)\n",
        "\n",
        "    # Assign A_matrix to the upper-left block\n",
        "    C[:N, :N] = A_matrix\n",
        "\n",
        "    # Assign B_matrix to the lower-right block\n",
        "    C[N:N+M, N:N+M] = B_matrix\n",
        "\n",
        "    return C\n",
        "\n",
        "def tensor_product(A, B):\n",
        "    return KroneckerProduct(A, B)"
      ],
      "metadata": {
        "id": "UqAjTyi5JDCh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# R matrix\n",
        "R_matrix = np.array([\n",
        "    [ np.exp(-4j * np.pi / 5), 0                      ],\n",
        "    [ 0                      , np.exp(3j * np.pi / 5) ]\n",
        "])\n",
        "\n",
        "R_tt1 = symbols(\"R_tt1\")  # Top-left diagonal\n",
        "R_ttt = symbols(\"R_ttt\")  # Bottom-right diagonal\n",
        "\n",
        "sym_R = Matrix([\n",
        "    [R_tt1, 0],\n",
        "    [0, R_ttt]\n",
        "])\n",
        "\n",
        "# F matrix\n",
        "phi = (1 + np.sqrt(5)) / 2  # Golden ratio\n",
        "F_matrix = np.array([\n",
        "    [ 1/phi          , np.sqrt(1/phi) ],\n",
        "    [ np.sqrt(1/phi) , -1/phi         ]\n",
        "])\n",
        "\n",
        "F_11 =  symbols(\"F_11\")\n",
        "F_12 =  symbols(\"F_12\")\n",
        "F_21 =  symbols(\"F_21\")\n",
        "F_22 =  symbols(\"F_22\")\n",
        "\n",
        "sym_F = Matrix([\n",
        "    [F_11, F_12],\n",
        "    [F_21, F_22]\n",
        "])\n",
        "\n",
        "# Substitution dictionary\n",
        "subs = {\n",
        "    R_tt1: R_matrix[0, 0],\n",
        "    R_ttt: R_matrix[1, 1],\n",
        "    F_11: F_matrix[0, 0],\n",
        "    F_12: F_matrix[1, 0],\n",
        "    F_21: F_matrix[0, 1],\n",
        "    F_22: F_matrix[1, 1]\n",
        "}\n",
        "\n",
        "# Permutation matrix\n",
        "I_2 = eye(2)\n",
        "\n",
        "I_5 = eye(5)\n",
        "I_5.row_swap(0, 3)\n",
        "P14 = I_5\n"
      ],
      "metadata": {
        "id": "AoTPVOfuI4KV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Braid representations\n",
        "\n",
        "rho_1 = direct_sum(R_ttt, tensor_product(sym_R, I_2).doit())\n",
        "\n",
        "rho_2 = direct_sum(R_ttt, tensor_product(sym_F * sym_R * sym_F, I_2).doit())\n",
        "\n",
        "rho_3 = P14 * direct_sum(R_ttt, direct_sum(sym_R, sym_F * sym_R * sym_F)) * P14\n",
        "\n",
        "rho_4 = direct_sum(R_ttt, tensor_product(I_2, sym_F * sym_R * sym_F).doit())\n",
        "\n",
        "rho_5 = direct_sum(R_ttt, tensor_product(I_2, sym_R).doit())\n",
        "\n",
        "# CNOT gate\n",
        "cnot_gate = Matrix([\n",
        "    [1, 0, 0, 0],\n",
        "    [0, 1, 0, 0],\n",
        "    [0, 0, 0, 1],\n",
        "    [0, 0, 1, 0]\n",
        "])"
      ],
      "metadata": {
        "id": "_75t-InJJV0T"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GateApproxEnv(gym.Env):\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, braid_gates, target_gate, subs, max_length,\n",
        "                 alpha, beta, gamma, local_equivalence_class=False):\n",
        "        super(GateApproxEnv, self).__init__()\n",
        "\n",
        "        self.max_length = max_length\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.gamma = gamma\n",
        "        self.local_equivalence_class = local_equivalence_class\n",
        "\n",
        "        # Precompute numeric versions of braid_gates\n",
        "        self.braid_gates = []\n",
        "        for g in braid_gates:\n",
        "            g_evaluated = g.subs(subs).evalf()\n",
        "            if any(sym.is_symbol for sym in g_evaluated):\n",
        "                raise ValueError(\"Not all symbols substituted in a braid gate.\")\n",
        "            self.braid_gates.append(np.array(g_evaluated.tolist(), dtype=complex))\n",
        "\n",
        "        # Precompute numeric target gate\n",
        "        t_evaluated = target_gate.subs(subs).evalf()\n",
        "        if any(sym.is_symbol for sym in t_evaluated):\n",
        "            raise ValueError(\"Not all symbols substituted in target_gate.\")\n",
        "        self.target_gate = np.array(t_evaluated.tolist(), dtype=complex)\n",
        "\n",
        "        # Action space: One action per braid gate\n",
        "        self.action_space = spaces.Discrete(len(self.braid_gates))\n",
        "\n",
        "        # Observation: Flattened real+imag parts of the 5x5 gate = 50-dim vector\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(50,), dtype=np.float64)\n",
        "\n",
        "        self.reset_composition()\n",
        "\n",
        "    def reset_composition(self):\n",
        "        \"\"\"Initialize the gate composition as a numeric 5x5 identity matrix.\"\"\"\n",
        "        self.current_composition = np.eye(5, dtype=complex)\n",
        "        self.current_length = 0\n",
        "        self.gate_stack = []\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.reset_composition()\n",
        "        self.current_step = 0\n",
        "        info = {}\n",
        "\n",
        "        # Randomize the episode length between 1 and max_length\n",
        "        self.random_episode_length = random.randint(1, self.max_length)\n",
        "\n",
        "        return self._get_obs(), info\n",
        "\n",
        "    def take_action(self, action):\n",
        "        if self.current_length < self.max_length:\n",
        "            # Numeric matrix multiplication only\n",
        "            self.current_composition = self.current_composition @ self.braid_gates[action]\n",
        "            if action < 5:\n",
        "                #self.gate_stack.append(f\"rho_{action+1}\")\n",
        "                self.gate_stack.append(f\"{action}\")\n",
        "            else:\n",
        "                #self.gate_stack.append(f\"inv_{action-4}\")\n",
        "                self.gate_stack.append(f\"{action}\")\n",
        "            self.current_length += 1\n",
        "        else:\n",
        "            print(\"Warning: Maximum composition length reached. No action taken.\")\n",
        "\n",
        "    def compute_reward(self):\n",
        "        # Current composition is already numeric\n",
        "        M = self.current_composition\n",
        "        T = self.target_gate\n",
        "\n",
        "        # Leakage: abs(M[0,0])\n",
        "        leakage = np.abs(M[0,0])\n",
        "\n",
        "        # Extract 4x4 submatrix\n",
        "        M_4x4 = M[1:5, 1:5]\n",
        "\n",
        "        # Unitarity check\n",
        "        UdagU = M_4x4.conjugate().T @ M_4x4\n",
        "        unitarity_error = self.schatten_p_norm(UdagU - np.eye(4), 1)\n",
        "\n",
        "        if self.local_equivalence_class:\n",
        "            closeness_error = self.local_equivalence_distance(T, M_4x4)\n",
        "        else:\n",
        "            # Closeness: Schatten p-norm\n",
        "            A_normalized = M_4x4 / self.schatten_p_norm(M_4x4, 2)\n",
        "            T_normalized = T / self.schatten_p_norm(T, 2)\n",
        "\n",
        "            closeness_error = self.schatten_p_norm(A_normalized - T_normalized, 2)\n",
        "\n",
        "\n",
        "        # Reward (negative weighted sum)\n",
        "        reward = - (self.alpha * leakage + self.beta * closeness_error + self.gamma * unitarity_error)\n",
        "        #reward = - (self.gamma * unitarity_error)\n",
        "\n",
        "        return float(leakage), float(unitarity_error), float(closeness_error), float(reward)\n",
        "\n",
        "    def step(self, action):\n",
        "        self.take_action(action)\n",
        "        self.current_step += 1\n",
        "\n",
        "        terminated = (self.current_step >= self.random_episode_length)\n",
        "        #terminated = (self.current_length >= self.max_length)\n",
        "        truncated = False\n",
        "\n",
        "        _, _, _, final_reward = self.compute_reward()\n",
        "        if terminated:\n",
        "            reward = final_reward\n",
        "        else:\n",
        "            reward = final_reward * 0.01\n",
        "\n",
        "        obs = self._get_obs()\n",
        "        info = {}\n",
        "        return obs, reward, terminated, truncated, info\n",
        "\n",
        "    def _get_obs(self):\n",
        "        # current_composition is numeric, just flatten\n",
        "        M = self.current_composition\n",
        "        obs = np.concatenate([M.real.flatten(), M.imag.flatten()])\n",
        "        return obs\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        pass\n",
        "\n",
        "    \"\"\"\n",
        "    def schatten_p_norm(self, T, p):\n",
        "\n",
        "        # Compute |T| = sqrt(T^† T)\n",
        "        abs_T = sqrtm(T.conj().T @ T)\n",
        "\n",
        "        # Compute |T|^p\n",
        "        abs_T_p = np.linalg.matrix_power(abs_T, p)\n",
        "\n",
        "        # Compute the trace of |T|^p\n",
        "        trace_value = np.trace(abs_T_p)\n",
        "\n",
        "        # Compute the Schatten p-norm\n",
        "        schatten_norm = np.real(trace_value)**(1/p)\n",
        "\n",
        "        return schatten_norm\n",
        "    \"\"\"\n",
        "\n",
        "    def schatten_p_norm(self, T, p):\n",
        "        \"\"\"\n",
        "        Compute the Schatten p-norm of a matrix T using its singular values.\n",
        "        \"\"\"\n",
        "        # Ensure T is a NumPy array\n",
        "        T = np.array(T, dtype=complex)\n",
        "\n",
        "        # Compute singular values of T\n",
        "        singular_values = np.linalg.svd(T, compute_uv=False)\n",
        "\n",
        "        # Compute Schatten p-norm\n",
        "        if p == np.inf:  # Special case for p = infinity\n",
        "            schatten_norm = np.max(singular_values)\n",
        "        elif p == 1:  # Special case for p = 1 (nuclear norm)\n",
        "            schatten_norm = np.sum(singular_values)\n",
        "        else:\n",
        "            # General case for arbitrary p\n",
        "            schatten_norm = (np.sum(singular_values**p))**(1/p)\n",
        "\n",
        "        return schatten_norm\n",
        "\n",
        "\n",
        "\n",
        "    def compute_makhlin_invariants(self, U):\n",
        "\n",
        "        i = 1j  # Complex unit (sqrt(-1))\n",
        "        Q = (1 / np.sqrt(2)) * np.array([\n",
        "            [1,  0,  0,  i],\n",
        "            [0,  i,  1,  0],\n",
        "            [0,  i, -1,  0],\n",
        "            [1,  0,  0, -i]\n",
        "        ], dtype=complex)\n",
        "\n",
        "        # Compute U_B = Q^\\dagger U Q\n",
        "        U_B = Q.conjugate().T @ U @ Q\n",
        "\n",
        "        # Makhlin matrix: m_U = (U_B)^T U_B\n",
        "        m_U = (U_B.T) @ U_B\n",
        "\n",
        "        # Compute trace and related quantities\n",
        "        tr_mU = np.trace(m_U)\n",
        "        tr_mU2 = np.trace(m_U @ m_U)\n",
        "        det_U = np.linalg.det(U)  # determinant of U\n",
        "\n",
        "        if np.abs(det_U) < 1e-12:\n",
        "            print(\"Warning: Determinant is very small, adding regularization.\")\n",
        "            det_U += 1e-12\n",
        "\n",
        "\n",
        "        # Compute complex quantity: (tr^2(m_U) / (16 * det(U)))\n",
        "        complex_val = (tr_mU**2) / (16.0 * det_U)\n",
        "\n",
        "        # g_1 = Re{complex_val}\n",
        "        g_1 = complex_val.real\n",
        "\n",
        "        # g_2 = Im{complex_val}\n",
        "        g_2 = complex_val.imag\n",
        "\n",
        "        # g_3 = (tr^2(m_U) - tr(m_U^2)) / (4 * det(U))\n",
        "        g_3 = ((tr_mU**2) - tr_mU2) / (4.0 * det_U)\n",
        "\n",
        "        return (g_1, g_2, g_3)\n",
        "\n",
        "    def local_equivalence_distance(self, E, U):\n",
        "        \"\"\"\n",
        "        Compute the closeness measure d_E(U) using the Makhlin invariants.\n",
        "\n",
        "        d_E(U) = sum_{i=1}^3 (Δg_i)^2, where Δg_i = |g_i(E) - g_i(U)|\n",
        "        \"\"\"\n",
        "        # Compute Makhlin invariants for E and U\n",
        "        gE = self.compute_makhlin_invariants(E)\n",
        "        gU = self.compute_makhlin_invariants(U)\n",
        "\n",
        "        # Compute Δg_i and sum their squares\n",
        "        diff_squares = [(abs(e - u))**2 for e, u in zip(gE, gU)]\n",
        "        d_EU = sum(diff_squares)\n",
        "        return d_EU\n",
        "\n"
      ],
      "metadata": {
        "id": "LWvZUDV3JZHQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "braid_gates = [rho_1, rho_2, rho_3, rho_4, rho_5]\n",
        "\n",
        "\"\"\"\n",
        "braid_gates = [\n",
        "        rho_1,       rho_2,       rho_3,       rho_4,       rho_5,\n",
        "        rho_1.inv(), rho_2.inv(), rho_3.inv(), rho_4.inv(), rho_5.inv()\n",
        "    ]\n",
        "\"\"\"\n",
        "\n",
        "target_gate = cnot_gate"
      ],
      "metadata": {
        "id": "XVo2YDUPJbQT"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate environment and model\n",
        "env = GateApproxEnv(\n",
        "    braid_gates=braid_gates,\n",
        "    target_gate=target_gate,\n",
        "    subs=subs,\n",
        "    max_length=SEQUENCE_LENGTH,\n",
        "    alpha=ALPHA,\n",
        "    beta=BETA,\n",
        "    gamma=GAMMA,\n",
        "    local_equivalence_class=True\n",
        ")"
      ],
      "metadata": {
        "id": "GoMABSVCJc1S"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_timesteps = 1000000\n",
        "verbose = 1\n",
        "\n",
        "policy_kwargs = dict(net_arch=[256 for _ in range(9)], activation_fn=torch.nn.GELU)\n",
        "\n",
        "#device = xm.xla_device() <--- Too Slow\n",
        "device = \"cuda\"\n",
        "\n",
        "model = DQN(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    #policy_kwargs=policy_kwargs,\n",
        "    #device=device,\n",
        "    verbose=verbose,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    gamma=GAMMA,\n",
        "    tensorboard_log=\"./tensorboard_logs/\"\n",
        "    )\n",
        "\n",
        "model.learn(total_timesteps=total_timesteps)\n"
      ],
      "metadata": {
        "id": "E4QJ2qcGJfOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_policy(env, model, num_sequences):\n",
        "\n",
        "    # Determine the maximum width of the Operator column dynamically\n",
        "    max_operator_width = SEQUENCE_LENGTH\n",
        "    operator_column_width = max(max_operator_width, 10)  # At least 10 for aesthetics\n",
        "\n",
        "    # Print table header with dynamically adjusted width\n",
        "    print(f\"{'Operator':<{operator_column_width}} | {'Closeness':<10} | {'Leakage':<10} | {'Unitarity':<10}\")\n",
        "    print(\"-\" * (operator_column_width + 34))  # Adjust divider length based on width\n",
        "\n",
        "    for seq in tqdm(range(num_sequences)):\n",
        "        #print(f\"--- Evaluating Sequence {seq + 1} ---\")\n",
        "        obs, _ = env.reset()\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            # Use the trained policy to sample an action\n",
        "\n",
        "            #lstm_states = None\n",
        "            #num_envs = 1\n",
        "            #episode_starts = np.ones((num_envs,), dtype=bool)\n",
        "\n",
        "            action, _ = model.predict(obs, deterministic=False)\n",
        "            obs, _, terminated, truncated, _ = env.step(action)\n",
        "            done = terminated or truncated\n",
        "\n",
        "        t = ''.join(map(str, env.gate_stack))\n",
        "\n",
        "        leakage, unitarity_error, closeness_error, _ = env.compute_reward()\n",
        "\n",
        "        if unitarity_error < 0.0001:\n",
        "            unitarity_error = 0.0\n",
        "\n",
        "        if (leakage > 0.8) and (closeness_error < .001):\n",
        "\n",
        "\n",
        "            # Print the results in a clean tabular format with dynamic width\n",
        "           print(f\"{t:<{operator_column_width}} | {closeness_error:<10.4e} | {leakage:<10.3f} | {unitarity_error:<10.3e}\")"
      ],
      "metadata": {
        "id": "sEOXLEXkd3Q0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_policy(env, model, num_sequences=10000)"
      ],
      "metadata": {
        "id": "GdqhaXeZJgvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "test = [\"30\",\n",
        "        \"880\",\n",
        "        \"5300\",\n",
        "        \"48440\",\n",
        "        \"553000\",\n",
        "        \"4334300\",\n",
        "        \"37770000\",\n",
        "        \"441001048\",\n",
        "        \"2555337582\",\n",
        "        \"59672955693\",\n",
        "        \"374050007970\",\n",
        "        \"306947382105\",\n",
        "        \"6595888969003\",\n",
        "        \"75139699757375\",\n",
        "        \"78450807782427077787\",\n",
        "        \"287430798424700981936977\"\n",
        "        ]\n",
        "\"\"\"\n",
        "test = [\n",
        "    \"000\",\n",
        "    \"0000\",\n",
        "    \"00000\",\n",
        "    \"222000\",\n",
        "    \"0000000\",\n",
        "    \"00000000\",\n",
        "    \"000000000\",\n",
        "    \"2221001222\",\n",
        "    \"22210012220\",\n",
        "    \"223443100122\",\n",
        "    \"2213404301242\",\n",
        "    \"34224334310031224\",\n",
        "    \"242314040312211412221\",\n",
        "    \"422211222020214000112021\",\n",
        "    \"101422102223130431111322222\",\n",
        "    \"31423322434332420442310301422\",\n",
        "    \"222223043422422024043333320003\",\n",
        "    \"2344130440331032213334400344312\",\n",
        "    \"423330314001220244224333334034032\",\n",
        "    \"132424244140142042111112011202122020400\",\n",
        "    \"231333001244422220433403402422343302043\"\n",
        "]"
      ],
      "metadata": {
        "id": "hNxyExMOTDMj"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def construct_gate_from_string(string_of_numbers, env):\n",
        "\n",
        "    test_gate = [ch for ch in string_of_numbers]\n",
        "\n",
        "    for i in test_gate:\n",
        "        env.take_action(int(i))\n",
        "\n",
        "    return env\n"
      ],
      "metadata": {
        "id": "DFJ4Ne4ZDIqs"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate environment and model\n",
        "env = GateApproxEnv(\n",
        "    braid_gates=braid_gates,\n",
        "    target_gate=target_gate,\n",
        "    subs=subs,\n",
        "    max_length=SEQUENCE_LENGTH,\n",
        "    alpha=ALPHA,\n",
        "    beta=BETA,\n",
        "    gamma=GAMMA,\n",
        "    local_equivalence_class=True\n",
        ")\n",
        "\n",
        "# Determine the maximum width of the Operator column dynamically\n",
        "max_operator_width = max(len(str(t)) for t in test)\n",
        "operator_column_width = max(max_operator_width, 10)  # At least 10 for aesthetics\n",
        "\n",
        "# Print table header with dynamically adjusted width\n",
        "print(f\"{'Operator':<{operator_column_width}} | {'Closeness':<10} | {'Leakage':<10} | {'Unitarity':<10}\")\n",
        "print(\"-\" * (operator_column_width + 34))  # Adjust divider length based on width\n",
        "\n",
        "# Iterate over the test cases and compute metrics\n",
        "for t in test:\n",
        "    env.reset_composition()\n",
        "    gate_object = construct_gate_from_string(t, env)\n",
        "    leakage, unitarity_error, closeness_error, total_error = gate_object.compute_reward()\n",
        "\n",
        "    if unitarity_error < 0.0001:\n",
        "        unitarity_error = 0.0\n",
        "\n",
        "    # Print the results in a clean tabular format with dynamic width\n",
        "    print(f\"{t:<{operator_column_width}} | {closeness_error:<10.3e} | {leakage:<10.3f} | {unitarity_error:<10.3e}\")\n"
      ],
      "metadata": {
        "id": "5HPNtjNPfZvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3efbf7df-f1fd-4f8d-d9aa-e9462d698f4a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Operator                                | Closeness  | Leakage    | Unitarity \n",
            "-------------------------------------------------------------------------\n",
            "000                                     | 5.000e+00  | 1.000      | 0.000e+00 \n",
            "0000                                    | 5.000e+00  | 1.000      | 0.000e+00 \n",
            "00000                                   | 5.000e+00  | 1.000      | 0.000e+00 \n",
            "222000                                  | 2.908e+00  | 0.954      | 9.017e-02 \n",
            "0000000                                 | 5.000e+00  | 1.000      | 0.000e+00 \n",
            "00000000                                | 5.000e+00  | 1.000      | 0.000e+00 \n",
            "000000000                               | 5.000e+00  | 1.000      | 0.000e+00 \n",
            "2221001222                              | 4.635e-01  | 0.976      | 4.760e-02 \n",
            "22210012220                             | 4.635e-01  | 0.976      | 4.760e-02 \n",
            "223443100122                            | 2.169e-05  | 0.976      | 4.760e-02 \n",
            "2213404301242                           | 2.169e-05  | 0.976      | 4.760e-02 \n",
            "34224334310031224                       | 2.169e-05  | 0.976      | 4.760e-02 \n",
            "242314040312211412221                   | 9.434e-02  | 0.992      | 1.682e-02 \n",
            "422211222020214000112021                | 7.829e-03  | 0.995      | 1.037e-02 \n",
            "101422102223130431111322222             | 1.232e-03  | 0.994      | 1.152e-02 \n",
            "31423322434332420442310301422           | 1.060e-04  | 0.995      | 9.638e-03 \n",
            "222223043422422024043333320003          | 7.779e-09  | 0.998      | 3.946e-03 \n",
            "2344130440331032213334400344312         | 2.197e-08  | 0.997      | 5.305e-03 \n",
            "423330314001220244224333334034032       | 7.779e-09  | 0.998      | 3.946e-03 \n",
            "132424244140142042111112011202122020400 | 2.058e-04  | 0.999      | 1.054e-03 \n",
            "231333001244422220433403402422343302043 | 7.779e-09  | 0.998      | 3.946e-03 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pR8NyAdhDFPT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}